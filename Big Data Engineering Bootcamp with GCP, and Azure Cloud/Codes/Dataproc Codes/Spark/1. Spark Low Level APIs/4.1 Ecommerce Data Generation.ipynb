{"cells": [{"cell_type": "markdown", "id": "90b7510c-c4d3-4314-8f68-b2b42b1e5dd3", "metadata": {}, "source": "# Ecommerce Test Data Generation"}, {"cell_type": "markdown", "id": "5e334bf0-42ef-4cb4-bb02-021a26d6f889", "metadata": {}, "source": "This  contains a set of e-commerce data CSV files designed for teaching purposes. The data is modeled to simulate a real-world e-commerce business, and it is structured in a way that allows you to demonstrate various Spark operations and data manipulations.\n\nThe data covers multiple entities like customers, orders, items, payments, and shippings, and is available in multiple sizes to allow for different use cases in Spark processing."}, {"cell_type": "code", "execution_count": null, "id": "68e0c0c4-556e-4edb-b415-3259123ec04f", "metadata": {}, "outputs": [], "source": "import pandas as pd\nimport numpy as np\nimport os\nimport random\nimport math\nimport glob\n\n# Set a seed for reproducibility\nrandom.seed(42)\nnp.random.seed(42)\n\ndef generate_data(num_rows, table_name, customers=None):\n    \"\"\"Generates a DataFrame based on table_name and returns it.\"\"\"\n    if table_name == \"customers\":\n        data = pd.DataFrame({\n            'customer_id': np.arange(num_rows),\n            'name': [f'Customer_{i}' for i in range(num_rows)],\n            'city': np.random.choice(['Mumbai', 'Delhi', 'Bangalore', 'Chennai', 'Kolkata', 'Hyderabad', 'Pune', 'Ahmedabad'], num_rows),\n            'state': np.random.choice(['Maharashtra', 'Delhi', 'Karnataka', 'Tamil Nadu', 'West Bengal', 'Telangana', 'Gujarat'], num_rows),\n            'country': 'India',\n            'registration_date': pd.to_datetime('2023-01-01') + pd.to_timedelta(np.random.randint(0, 365, num_rows), unit='D'),\n            'is_active': np.random.choice([True, False], num_rows)\n        })\n    elif table_name == \"orders\":\n        if customers is None:\n            raise ValueError(\"Customer data must be provided for generating orders.\")\n        data = pd.DataFrame({\n            'order_id': np.arange(num_rows),\n            'customer_id': np.random.choice(customers['customer_id'], num_rows),\n            'order_date': pd.to_datetime('2024-01-01') + pd.to_timedelta(np.random.randint(0, 365, num_rows), unit='D'),\n            'total_amount': np.random.uniform(10, 1000, num_rows),\n            'status': np.random.choice(['Pending', 'Shipped', 'Delivered', 'Cancelled'], num_rows)\n        })\n    elif table_name == \"items\":\n        data = pd.DataFrame({\n            'item_id': np.arange(num_rows),\n            'order_id': np.random.randint(0, num_rows, num_rows),\n            'item_name': [f'Item_{i}' for i in range(num_rows)],\n            'category': np.random.choice(['Electronics', 'Clothing', 'Books', 'Home', 'Sports'], num_rows),\n            'price': np.random.uniform(5, 500, num_rows),\n        })\n    elif table_name == \"payments\":\n        data = pd.DataFrame({\n            'payment_id': np.arange(num_rows),\n            'order_id': np.random.randint(0, num_rows, num_rows),\n            'payment_date': pd.to_datetime('2024-01-01') + pd.to_timedelta(np.random.randint(0, 365, num_rows), unit='D'),\n            'amount': np.random.uniform(10, 1000, num_rows),\n            'payment_method': np.random.choice(['Credit Card', 'Debit Card', 'PayPal', 'UPI'], num_rows)\n        })\n    elif table_name == \"shippings\":\n        data = pd.DataFrame({\n            'shipping_id': np.arange(num_rows),\n            'order_id': np.random.randint(0, num_rows, num_rows),\n            'shipping_date': pd.to_datetime('2024-01-01') + pd.to_timedelta(np.random.randint(0, 365, num_rows), unit='D'),\n            'shipping_address': [f'Address_{i}' for i in range(num_rows)],\n            'shipping_method': np.random.choice(['Standard', 'Express'], num_rows)\n        })\n    else:\n        return None\n    return data\n\ndef write_csv(data, file_path):\n    \"\"\"Writes DataFrame to a CSV file.\"\"\"\n    data.to_csv(file_path, index=False)\n\ndef estimate_row_size(data):\n    \"\"\"Estimate the average row size in bytes.\"\"\"\n    buffer = data.head(10)  # Take the first 10 rows to estimate size\n    tmp_file = \"temp_estimation.csv\"\n    buffer.to_csv(tmp_file, index=False)\n    file_size = os.path.getsize(tmp_file)\n    os.remove(tmp_file)\n    avg_row_size = file_size / len(buffer)\n    return avg_row_size\n\ndef generate_ecommerce_data(file_sizes_mb, output_dir):\n    \"\"\"Generates multiple CSV files of specified sizes with e-commerce data.\"\"\"\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    table_names = [\"customers\", \"orders\", \"items\", \"payments\", \"shippings\"]\n\n    for size_mb in file_sizes_mb:\n        size_dir = os.path.join(output_dir, f\"{size_mb}MB\")\n        os.makedirs(size_dir, exist_ok=True)\n\n        # Generate customers first for other tables to reference\n        customers = generate_data(10000, \"customers\")\n        avg_row_size = estimate_row_size(customers)\n        target_size_bytes = size_mb * 1024 * 1024\n        num_rows_customers = math.ceil(target_size_bytes / avg_row_size)\n\n        # Generate the full dataset for customers\n        customers = generate_data(num_rows_customers, \"customers\")\n        write_csv(customers, os.path.join(size_dir, \"customers.csv\"))\n        \n        print(f\"Generated customers CSV with actual size: {os.path.getsize(os.path.join(size_dir, 'customers.csv')) / (1024 * 1024):.2f}MB\")\n        \n        # Now generate other tables using the customer data\n        for table_name in table_names[1:]:  # skip 'customers'\n            if table_name == \"orders\":\n                orders = generate_data(num_rows_customers, table_name, customers=customers)\n                write_csv(orders, os.path.join(size_dir, \"orders.csv\"))\n            else:\n                orders = pd.read_csv(os.path.join(size_dir, \"orders.csv\"))\n                orders_count = len(orders)\n                table_data = generate_data(orders_count, table_name)\n                write_csv(table_data, os.path.join(size_dir, f\"{table_name}.csv\"))\n            \n            print(f\"Generated {table_name} CSV with actual size: {os.path.getsize(os.path.join(size_dir, f'{table_name}.csv')) / (1024 * 1024):.2f}MB\")\n\n# Example usage\nfile_sizes_mb = [1,10,150,300,500,1100]  # Adjust as needed\noutput_directory = \"/content/ecommerce_data\"\n\ngenerate_ecommerce_data(file_sizes_mb, output_directory)\nprint(f\"Data files generated in {output_directory}\")\n\n# Display a sample\nsample_file = glob.glob(os.path.join(output_directory, \"**/*.csv\"), recursive=True)[0]\nprint(f\"\\nSample data from: {sample_file}\")\nprint(pd.read_csv(sample_file).head())"}, {"cell_type": "code", "execution_count": 1, "id": "097935f6-e184-47c5-846f-56c8e7f32547", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Found 8 items\n-rw-r--r--   2 root       hadoop  343317147 2025-01-20 10:42 /tmp/customers.csv\n-rw-r--r--   2 root       hadoop   10528211 2025-01-20 10:31 /tmp/customers_10mb.csv\n-rw-r--r--   2 mayank0953 hadoop    1060750 2025-01-20 10:23 /tmp/customers_1mb.csv\n-rw-r--r--   2 mayank0953 hadoop  570783961 2025-01-22 17:12 /tmp/customers_500mb.csv\ndrwxr-xr-x   - anonymous  hadoop          0 2025-01-23 16:41 /tmp/external\ndrwxrwxrwt   - hdfs       hadoop          0 2025-01-20 09:57 /tmp/hadoop-yarn\ndrwx-wx-wx   - hive       hadoop          0 2025-01-20 09:57 /tmp/hive\n-rw-r--r--   2 root       hadoop         83 2025-01-26 19:11 /tmp/inputhdfsdbz.txt\n"}], "source": "! hadoop fs -ls /tmp/"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.8"}}, "nbformat": 4, "nbformat_minor": 5}