{"cells": [{"cell_type": "code", "execution_count": 28, "id": "51ff3f63-8b4a-4724-97c7-aa3fc22ba808", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/01/29 16:10:27 INFO SparkEnv: Registering MapOutputTracker\n25/01/29 16:10:27 INFO SparkEnv: Registering BlockManagerMaster\n25/01/29 16:10:27 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n25/01/29 16:10:27 INFO SparkEnv: Registering OutputCommitCoordinator\n"}], "source": "from pyspark.sql import SparkSession \n\nspark = SparkSession.builder \\\n.appName('Spark_Parallize_and_Partition')\\\n.master('yarn')\\\n.getOrCreate()"}, {"cell_type": "code", "execution_count": 31, "id": "13ac312e-7d90-4110-b51d-3e9e53a3323c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Found 8 items\n-rw-r--r--   2 root       hadoop    327.4 M 2025-01-20 10:42 /tmp/customers.csv\n-rw-r--r--   2 root       hadoop     10.0 M 2025-01-20 10:31 /tmp/customers_10mb.csv\n-rw-r--r--   2 mayank0953 hadoop      1.0 M 2025-01-20 10:23 /tmp/customers_1mb.csv\n-rw-r--r--   2 mayank0953 hadoop    544.3 M 2025-01-22 17:12 /tmp/customers_500mb.csv\ndrwxr-xr-x   - anonymous  hadoop          0 2025-01-23 16:41 /tmp/external\ndrwxrwxrwt   - hdfs       hadoop          0 2025-01-20 09:57 /tmp/hadoop-yarn\ndrwx-wx-wx   - hive       hadoop          0 2025-01-20 09:57 /tmp/hive\n-rw-r--r--   2 root       hadoop         83 2025-01-26 19:11 /tmp/inputhdfsdbz.txt\n"}], "source": "!hadoop fs -ls -h /tmp/"}, {"cell_type": "code", "execution_count": 32, "id": "e5f94b28-b8f6-45e7-aa21-8effc68bff87", "metadata": {}, "outputs": [], "source": "data = [\n    \"Goku Vegeta Gohan\",\n    \"Goku Frieza Goku\",\n    \"Vegeta Goku Frieza Gohan\",\n    \"Gohan Frieza Goku Goku\" ]\n\nlocal_rdd = spark.sparkContext.parallelize(data)\n\nbig_hdfs_path = '/tmp/customers_500mb.csv'\n\nbig_rdd_from_hdfs = spark.sparkContext.textFile(big_hdfs_path)\n\n\n\nsmall_hdfs_path = '/tmp/customers_1mb.csv'\n\nsmall_rdd_from_hdfs = spark.sparkContext.textFile(small_hdfs_path)\n"}, {"cell_type": "code", "execution_count": null, "id": "c978f8ff-97d7-404f-bc02-e2ba7dd5f83c", "metadata": {}, "outputs": [], "source": "# get num of Partition from rdd => getNumPartition()"}, {"cell_type": "code", "execution_count": 33, "id": "1880337a-d8ac-43a6-b036-cf931736b750", "metadata": {}, "outputs": [{"data": {"text/plain": "5"}, "execution_count": 33, "metadata": {}, "output_type": "execute_result"}], "source": "# 544mb => 5 blocks => 5 partition\nbig_rdd_from_hdfs.getNumPartitions()"}, {"cell_type": "code", "execution_count": 34, "id": "b8f418cf-7639-4502-9df8-3ede4a8d643d", "metadata": {}, "outputs": [{"data": {"text/plain": "2"}, "execution_count": 34, "metadata": {}, "output_type": "execute_result"}], "source": "#1 mb => 1 block --> 1 partition ( This is wrong)\nsmall_rdd_from_hdfs.getNumPartitions()"}, {"cell_type": "code", "execution_count": 35, "id": "985b4c17-c137-4be9-90a0-6fb65d28fed0", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Max Partition Bytes: 134217728b\n"}], "source": "print(f\"Max Partition Bytes: {spark.conf.get('spark.sql.files.maxPartitionBytes')}\")"}, {"cell_type": "code", "execution_count": 36, "id": "8f740211-008d-4a85-bc02-0b2557599fa7", "metadata": {}, "outputs": [{"data": {"text/plain": "2"}, "execution_count": 36, "metadata": {}, "output_type": "execute_result"}], "source": "spark.sparkContext.defaultMinPartitions"}, {"cell_type": "code", "execution_count": 37, "id": "097de5da-ffc2-4719-87c9-44b1902943a4", "metadata": {}, "outputs": [{"data": {"text/plain": "4"}, "execution_count": 37, "metadata": {}, "output_type": "execute_result"}], "source": "local_rdd.getNumPartitions()"}, {"cell_type": "code", "execution_count": 38, "id": "17ca2b12-3dc0-4c35-9780-44b81597157c", "metadata": {}, "outputs": [{"data": {"text/plain": "4"}, "execution_count": 38, "metadata": {}, "output_type": "execute_result"}], "source": "spark.sparkContext.defaultParallelism"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.8"}}, "nbformat": 4, "nbformat_minor": 5}